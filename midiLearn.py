from scipy.io.wavfile import read as wavread
import numpy as np
from keras.models import Sequential
from keras.layers.convolutional import Conv1D
from keras.layers.core import Dense
from keras.layers.recurrent import LSTM
from keras.optimizers import RMSprop
from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping # first saves the best model, second loggs the training, third stops the training of the result does not improve
from keras.models import load_model # to load saved model.
from generateWavs import getFilteredDataList
import os.path
import librosa.core
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
import sklearn.preprocessing
from tqdm import tqdm

#parameters
lr = 0.005 # learning rate
wavFileName = "nylon_20.wav" # learn from this file



def train_model(cqts, combinations, lr):  # trains the model and returns the saved file's filename. (could also return the model, which is not necessarily identical to the saved one.)
	model_name = 'model.hd5'
	log_dir = 'TB_log'
	callbacks = []
	callbacks.append(TensorBoard(log_dir=log_dir)) # logs into the TB_log directory
	callbacks.append(ModelCheckpoint(filepath=model_name,   verbose=1, save_best_only=True, period=1)) # saves the model if the result is improved at the current epoch
	callbacks.append(EarlyStopping(patience = 3,verbose = 1))
	model = Sequential()
	#model.add(Conv1D(2,10,input_shape=cqts.shape))
	model.add(LSTM(combinations.shape[1],activation = "sigmoid", stateful = True, batch_input_shape = (12,cqts.shape[1],cqts.shape[2]))) # sigmoid activation, since the output is scaled between 0 and 1.	
	print("Model Summary: \n" + str(model.summary()))
	optimizer = RMSprop(lr = lr)
	model.compile(optimizer=optimizer, loss='mean_squared_error',  metrics=['mean_squared_error'])
	model.fit(cqts, combinations, nb_epoch=15, batch_size=12, shuffle=False,validation_split = 0.2, callbacks = callbacks)
	#not that dat is already shuffled in the function processWav.
	return model_name # model is saved with the ModelCheckpoint callback.


def cutWavByNotes(x, noteDurationInBeat, bpm, sampleRate): # x: wav data in numpy array
    bps = bpm / 60  # beat per sec
    noteDurationinSamples = (noteDurationInBeat * sampleRate) / bps  # note duration in samples
    # Checking if wav format is okay.
    numberOfNotes = (len(x)) / noteDurationinSamples
    if np.round(numberOfNotes) == numberOfNotes and np.round(noteDurationinSamples) == noteDurationinSamples:
        numberOfNotes = int(numberOfNotes)
        noteDurationinSamples = int(noteDurationinSamples)
    else:
        raise ValueError("In processWav function, the length of the data is ", len(x), " samples.",
                         "The length of a note is determined to be ", noteDurationinSamples, " samples",
                         "Which means that the total number of notes in the data is ", numberOfNotes,
                         "One of them is not an integer number. ")
    x = x.reshape(numberOfNotes, noteDurationinSamples)  # reshapes: every row is a note
    return x

# Reads a (filtered) wav file, and returns training data (cqt transormed samples and output vectors)
#Convention: In the wav file, each note of the note indicated in the combMatrix lasts for noteDurationInBeat beats.

def processWav(x,sampleRate, combMatrix = None):
	if combMatrix is None:
		if os.path.isfile("combinationMatrix.npy"):
			combMatrix = np.load("combinationMatrix.npy")
		else:
			raise ValueError("Process Wav needs the combination matrix ( generated by createMIDI), but file is not found.")

	# used variables
	sampleLength = 512 # in samples ( 44100 is not a multiple of 512...)
	# this depends on sound rendering/recording bpm
	noteDurationInBeat = 4  # sound duration in beats ( each sound is followed by silence of the same length.)
	bpm = 120
	#calculated variables:
	bps = bpm / 60 # beat per sec
	noteDurationinSamples = noteDurationInBeat * sampleRate / bps # note duration in samples
	xCut = cutWavByNotes(x,noteDurationInBeat,bpm,sampleRate)#each note in a row
	samples, combMatrix = shuffle(xCut, combMatrix, random_state=13002)  # shuffles matricies.


	samplesFromNote = int(np.floor(noteDurationinSamples / sampleLength)) # we are creating this many samples from one note.
	# repeating notes in the comb matrix
	combMatrixMaxs = np.max(combMatrix, 0)
	combMatrix = combMatrix.astype(np.float) / combMatrixMaxs
	combMatrix = np.tile(combMatrix,samplesFromNote).reshape(-1,combMatrix.shape[1]) # repeats each row as many times as many samples we create from a single note.
	print("combMatrix is normed by the vector ", combMatrixMaxs)

	#preparing samples
	samples = samples[:,:samplesFromNote*sampleLength] # cutting the end. (44100 is not a multiple of 512)

	samples = samples.flatten() # flat array
	#Shuffle is applied before reshape(sampleLengthm-1), samples from the same notes are following each other, but
	#note combinations are shuffled.
	print("Calculating CQTs")
	cqt = librosa.core.cqt(samples.astype(np.float),sampleRate,sampleLength)[:,:-1].transpose()
	cqt = librosa.core.logamplitude(cqt)
	cqts = sklearn.preprocessing.normalize(cqt,axis=1)

	if combMatrix.shape[0] != cqts.shape[0]:
		raise ValueError("After processing the wav file in processWav, the generated samples",
						 "and the generated combMatrix has different sizes. (First dimension should match.)\nShapes are: ",
						 "combMatrix: " , combMatrix.shape, "\n cqts: " , cqts.shape)
	return (cqts, combMatrix)


def get_data(fileName):
	#Reads data from disk if exists. If not, generates data from waw from wav file with name  fileName.
	dataFileName = fileName + "_trainData.npz"
	if os.path.isfile(dataFileName):
		print('Loading data from file ' + dataFileName)
		data = np.load(dataFileName)
		cqt_transform = data['cqt_transform']
		combinations = data['combinations']
	else:
		cqt_transform = None
		combinations = None
		print('Generating training data from waw.')
		(note_sample_list, sample_rate) = getFilteredDataList(fileName)
		while note_sample_list:
			print('Processing new x data. List size is ' + str(len(note_sample_list)))
			x =note_sample_list.pop()
			(cqt_transform_this, combinations_this) = processWav(x, sample_rate)
			if cqt_transform is None:
				cqt_transform = cqt_transform_this
				combinations = combinations_this
			else:
				cqt_transform = np.vstack([cqt_transform,cqt_transform_this])
				combinations = np.vstack([combinations, combinations_this])
		print("Data generation finished, saving it to disk.")
		np.savez(dataFileName,cqt_transform = cqt_transform, combinations = combinations)
		print('Data saved to disk for next training.')
	return (cqt_transform, combinations)

np.random.seed(13002) # for reproductivity. (fyi: '13' is 'B', '0' is 'O' and '2' is 'Z')
(cqt_transform, combinations) = get_data(wavFileName)

cqt_transform = cqt_transform[:,np.newaxis,:]
# Splitting the dataset to train (inc. validation) and test set.
cqt_transform_train, cqt_transform_test, combinations_train, combinations_test = train_test_split(cqt_transform,combinations, test_size = 0.15, random_state = 13002  )

#Train  ( chu - chu )
print("Training with :\ntrain_data shape: " , cqt_transform_train.shape, " label shape: ",combinations_train.shape)

trained_model_path = train_model(cqt_transform_train,combinations_train, lr)

#Load saved model and test on the test data
print("Reloadig the model from the hard drive and testing it using the test dataset.")
model = load_model(trained_model_path)
test_accuracy = model.evaluate(cqt_transform_test,combinations_test)[1] # returns the loss and accuracy in this order.
print("\nTest accuracy: " + str(test_accuracy))

print("See the training log by executing $ tensorboard --logdir='.'")

from scipy.io.wavfile import read as wavread
import numpy as np
import midi
from keras.models import Sequential
from keras.layers.convolutional import Conv1D
from keras.layers.recurrent import LSTM
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping # first saves the best model, second loggs the training, third stops the training of the result does not improve
from keras.models import load_model # to load saved model.
from generateWavs import getFilteredDataList
import os.path
import librosa.core
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle


def train_model(cqts, combinations, lr):  # trains the model and returns the saved file's filename. (could also return the model, which is not necessarily identical to the saved one.)
	model_name = 'model.hd5'
	log_dir = 'TB_log'
	callbacks = []
	callbacks.append(TensorBoard(log_dir=log_dir)) # logs into the TB_log directory
	callbacks.append(ModelCheckpoint(filepath=model_name,   verbose=1, save_best_only=True, period=1)) # saves the model if the result is improved at the current epoch
	callbacks.append(EarlyStopping(patience = 3,verbose = 1))
	model = Sequential()
	model.add(Conv1D(2,10,input_shape=(None,cqts.shape[1])))
	model.add(LSTM(cqts.shape[1],activation = "sigmoid", stateful = True)) # sigmoid activation, since the output is scaled between 0 and 1.
	print("Model Summary: \n" + str(model.summary()))
	adam = Adam(lr = lr)
	model.compile(optimizer=adam, loss='mean_squared_error',  metrics=['mean_squared_error'])
	model.fit(cqts, combinations, nb_epoch=15, batch_size=64, shuffle=False,validation_split = 0.2, callbacks = callbacks)
	#not that dat is already shuffled in the function processWav.
	return model_name # model is saved with the ModelCheckpoint callback.



# Reads a (filtered) wav file, and returns training data (cqt transormed samples and output vectors)
#Convention: In the wav file, each note of the note indicated in the combMatrix lasts for noteDurationInBeat beats.
#After each sound [but the last], there is silence, with the same length. ( Silence is cut off from the training data, but needed
# for filtering the sound in a prev. step.
def processWav(x,sampleRate, combMatrix = None):
	if combMatrix is None:
		if os.path.isfile("combinationMatrix.npy"):
			combMatrix = np.load("combinationMatrix.npy")
		else:
			raise ValueError("Process Wav needs the combination matrix ( generated by createMIDI), but file is not found.")

	# used variables
	sampleLength = 512 # in samples
	# this depends on sound rendering/recording bpm
	noteDurationInBeat = 4  # sound duration in beats ( each sound is followed by silence of the same length.)
	bpm = 120
	#calculated variables:
	bps = bpm / 60 # beat per sec
	noteDurationinSamples = noteDurationInBeat * sampleRate / bps # note duration in samples

	#Checking if wav format is okay.
	numberOfNotes = (len(x)+noteDurationinSamples) / (2.0*noteDurationinSamples) # there is silence after each not, but the last
	if np.round(numberOfNotes) == numberOfNotes:
		nuberOfNotes = int(noteDurationinSamples)
	else:
		raise ValueError("In processWav function, the length of the data is " , len(x) , " samples.",
						 "The length of a note is determined to be ", noteDurationinSamples, " samples",
						 "Which means that the total number of notes in the data is ", nuberOfNotes,
						 "which is not an integer number. \nDid you forgat that there is a silence after each",
						 "but the last note?")
	if numpy.mod(noteDurationinSamples ,sampleLength) !=0:
		raise ValueError("In prodessWav note duration is calculated to be " , noteDurationinSamples , "samples,"
						 "but each not should be devided to samples with legth ", sampleLength, "."
						 "Error: they are not multiple of each other.")

	numberOfRepeats = nuberOfNotes *1.0 / combMatrix.shape[0] # in a way file the note sequence of combMatrix may be repeated.
	if np.round(numberOfRepeats) == numberOfRepeats:
		numberOfRepeats = int(numberOfRepeats)
	else:
		raise ValueError("In processWav function, the length of the data is " , len(x) , " samples.",
						"the total number of notes in the data is ", nuberOfNotes,
						 "which is not a multiple of the notes in the combMatrix with a shape" , combMatrix.shape)


#Scaling removed, and moved after CQT.
	# scale to 0.0 -- 1.0 !!! #TODO is it the same at the frontend?
#	if x.dtype == 'int16':
#	    nb_bits = 16  # -> 16-bit wav files
#	elif x.dtype == 'int32':
#	    nb_bits = 32  # -> 32-bit wav files
#	max_nb_bit = float(2 ** (nb_bits - 1))
#	samples = x / (max_nb_bit + 1.0)  # samples is a numpy array of float representing the samples

	combMatrix = np.repeat(combMatrix, numberOfRepeats, 0)
	combMatrixMaxs = np.max(combMatrix, 0)
	combMatrix = combMatrix.astype(np.float) / combMatrixMaxs
	print("combMatrix is normed by the vector ", combMatrixMaxs)

	samples = samples.reshape(2*numberOfNotes-1,noteDurationinSamples)# reshapes: every row is a note [ every other is just silence]
	samples = samples[0::2] # removes parts where only silence is played.
	samples,combMatrix = shuffle(samples,combMatrix,random_state=13002) # shuffles matricies.
	samples = samples.reshape(sampleLength,-1) # reshapes so each row is a sample of a note.
	#Shuffle is applied before reshape(sampleLengthm-1), samples fromthe same notes are following each other, but
	#note combinations are shuffled.

	cqts = librosa.core.cqt (samples,sampleRate)
	cqts = librosa.core.logamplitude(cqts)
	cqts = cqts.astype(float) / np.max(cqts,0)



	if combMatrix.shape[0] != cqts.shape[0]:
		raise ValueError("After processing the wav file in processWav, the generated samples",
			  "and the generated combMatrix has different sizes. (First dimension should match.)\nShapes are: ",
						 "combMatrix: " , combMatrix.shape, "\n cqts: " , cqts.shape)

	return (cqts, combMatrix)


def get_data(fileName = 'trainingData.npz'):
#Reads data from disk if exists. If not, generates data from waw.
	if os.path.isfile(fileName):
		print('Loading data from file ' + fileName)
		data = np.load(fileName)
		cqt_transform = data['cqt_transform']
		combinations = data['combinations']
	else:
		cqt_transform = None
		combinations = None
		print('Generating training data from waw.')
		(note_sample_list, sample_rate) = getFilteredDataList()
		while note_sample_list:
			print('Processing new x data. List size is ' + str(len(note_sample_list)))
			x =note_sample_list.pop()
			(cqt_transform_this, combinations_this) = processWav(x, sample_rate)
			if cqt_transform is None:
				cqt_transform = cqt_transform_this
				combinations = combinations_this
			else:
				cqt_transform = np.vstack([cqt_transform,cqt_transform_this])
				combinations = np.vstack([combinations, combinations_this])
		print("Data generation finished, saving it to disk.")
		np.savez(fileName,cqt_transform = cqt_transform, combinations = combinations)
		print('Data saved to disk for next training.')
	return (cqt_transform, combinations)

np.random.seed(13002) # for reproductivity. (fyi: '13' is 'B', '0' is 'O' and '2' is 'Z')
(cqt_transform, combinations) = get_data()
# Splitting the dataset to train (inc. validation) and test set.
cqt_transform_train, cqt_transform_test, combinations_train, combinations_test = train_test_split(cqt_transform,combinations, test_size = 0.15, random_state = 13002  )

#Train  ( chu - chu )
print("Training")
trained_model_path = train_model(cqt_transform_train,combinations_train, 0.005)

#Load saved model and test on the test data
print("Reloadig the model from the hard drive and testing it using the test dataset.")
model = load_model(trained_model_path)
test_accuracy = model.evaluate(cqt_transform_test,combinations_test)[1] # returns the loss and accuracy in this order.
print("\nTest accuracy: " + str(test_accuracy))

print("See the training log by executing $ tensorboard --logdir='.'")
